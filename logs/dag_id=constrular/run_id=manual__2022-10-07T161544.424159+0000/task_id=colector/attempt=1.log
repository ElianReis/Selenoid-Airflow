[2022-10-07T16:15:47.280+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: constrular.colector manual__2022-10-07T16:15:44.424159+00:00 [queued]>
[2022-10-07T16:15:47.297+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: constrular.colector manual__2022-10-07T16:15:44.424159+00:00 [queued]>
[2022-10-07T16:15:47.297+0000] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2022-10-07T16:15:47.298+0000] {taskinstance.py:1363} INFO - Starting attempt 1 of 1
[2022-10-07T16:15:47.298+0000] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2022-10-07T16:15:47.315+0000] {taskinstance.py:1383} INFO - Executing <Task(PythonOperator): colector> on 2022-10-07 16:15:44.424159+00:00
[2022-10-07T16:15:47.321+0000] {standard_task_runner.py:54} INFO - Started process 2357 to run task
[2022-10-07T16:15:47.323+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'constrular', 'colector', 'manual__2022-10-07T16:15:44.424159+00:00', '--job-id', '430', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmp6snhxoe7']
[2022-10-07T16:15:47.323+0000] {standard_task_runner.py:83} INFO - Job 430: Subtask colector
[2022-10-07T16:15:47.324+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/***/dags/dag.py
[2022-10-07T16:15:47.789+0000] {task_command.py:384} INFO - Running <TaskInstance: constrular.colector manual__2022-10-07T16:15:44.424159+00:00 [running]> on host 9a36b0424536
[2022-10-07T16:15:47.853+0000] {taskinstance.py:1592} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=constrular
AIRFLOW_CTX_TASK_ID=colector
AIRFLOW_CTX_EXECUTION_DATE=2022-10-07T16:15:44.424159+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2022-10-07T16:15:44.424159+00:00
[2022-10-07T16:15:47.854+0000] {tasks.py:39} INFO - Defining DEC to export information
[2022-10-07T16:15:47.861+0000] {tasks.py:360} INFO - Reading prep dataframe
[2022-10-07T16:15:47.870+0000] {tasks.py:153} INFO - Instantiating the Browser with the requested settings
[2022-10-07T16:15:50.494+0000] {tasks.py:167} INFO - Browser configured
[2022-10-07T16:15:50.495+0000] {tasks.py:290} INFO - Removing nan URL values
[2022-10-07T16:15:50.496+0000] {tasks.py:291} INFO - Requested prices before: 1
[2022-10-07T16:15:50.499+0000] {tasks.py:296} INFO - Requested prices after: 1
[2022-10-07T16:16:05.259+0000] {tasks.py:390} INFO - Price of 1567322 - BUCHADEREDUCAO: R$ 0,97
[2022-10-07T16:16:05.260+0000] {tasks.py:329} INFO - Printing information
[2022-10-07T16:16:05.322+0000] {tasks.py:417} INFO - Saved screenshots and prices
[2022-10-07T16:16:05.322+0000] {tasks.py:248} INFO - Test passed
[2022-10-07T16:16:05.324+0000] {tasks.py:274} INFO - Requested prices: 1
[2022-10-07T16:16:05.324+0000] {tasks.py:275} INFO - Scraped prices: 1
[2022-10-07T16:16:05.324+0000] {tasks.py:276} INFO - Day of the scraping: 07/10/2022
[2022-10-07T16:16:05.334+0000] {python.py:177} INFO - Done. Returned value was: None
[2022-10-07T16:16:05.345+0000] {taskinstance.py:1406} INFO - Marking task as SUCCESS. dag_id=constrular, task_id=colector, execution_date=20221007T161544, start_date=20221007T161547, end_date=20221007T161605
[2022-10-07T16:16:05.398+0000] {local_task_job.py:164} INFO - Task exited with return code 0
[2022-10-07T16:16:05.417+0000] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
